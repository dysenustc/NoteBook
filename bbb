VINS-Mono[1][2][3]：
这是香港科技大学空中机器人实验室2017年发表于IEEE的一系列文章，主要内容围绕Mono Visual + IMU 来做SLAM。下面根据文章对其提出的VINS-Mono框架进行一个分析。
VINS-Mono主要包含以下几个部分: 
1、观测预处理（Measurement Preprocess）:对图像提取特征做特征匹配，然后输出跟踪特征序列，对IMU做预积分,输出两帧图像间的IMU积分结果；
2、初始化（Robust Initialization）: 采用纯视觉（Vision-Only Structure）估计相机运动和相对深度， IMU预积分也会得到一个相对运动, 二者做Alignment, 从而标定出尺度, 重力加速地, 速度, 和偏差（bias）；
3、后端融合优化（local BA）：状态向量包括：滑动窗口中的IMU状态、相机外参 +特征点的逆深度；残差项包括: marginalization提供的先验信息、IMU残差项 和visual残差项。优化完之后，得到各个时刻相机的位姿。
4、闭环检测和全局优化（Loop detection/Global Pose Graph Optimization）：VIO毕竟有累积误差, 所以跟常规visual SLA一样, 加入闭环检测, 然后优化一个位姿图，但是这里是只优化4 DoF，因为scale、roll和pitch是可观的, 误差只会在（x,y,z）和yaw四个维度上累积。（重力向量可以反映两个自由度）
 
图1-1 VINS-Mono系统流程图
作者认为，在初始化阶段，单目视觉SLAM和 运动结构比视觉惯性融合的稳定性更高，因为前者不依赖初始状态。因此，作者将imu和visual采用松耦合的方式得到初始状态。首先使用视觉构造运动结构（SFM），得到一个相对运动，然后利用imu预积分的相对运动进行匹配（Alignment），从而标定出尺度, 重力加速地, 速度, 和bias 。流程图如下所示：黑色虚线框即时初始化结构。
 
图1.2 VINS 初始化流程图
视觉观测预处理：
	视觉观测预处理基于滑窗法进行相机运动的估计，选取视差大的相邻帧进行特征提取，采用五点法得到相邻帧间的相对运动。三角化得到特征的3D 位置，使用PnP估计滑窗其他帧的位姿。最后对所有的观测到的特征点计算重投影误差，做BA。最后得到所有滑窗内关键帧的位姿和特征点的相对位置。根据camera坐标系和IMU坐标系的内参，可以将所有的变量变换到IMU坐标系。
IMU预积分：
	为了在视觉中融合IMU数据，需要将IMU观测值处理一个增量约束，通常的做法是采用IMU预积分操作（Pre-integration）。
	我们先来理解一下问什么需要对IMU数据进行预积分处理。
定义p_(b_k)^w，v_(b_k)^w，q_(b_k)^w分别表示IMU坐标系下第k个image相对与世界坐标系的位置、速度和四元数。它们满足迭代式：其中a_t^b，w_t^b 分别是IMU坐标系下的瞬时加速度和角速度。∆t是两幅图像的时间间隔。⊗表示四元数的乘法。
p_(b_(k+1))^w=p_(b_k)^w+v_(b_k)^w ∆t_k+∬_(t∈[k,k+1])▒〖(R_t^w a_t^b-g^w)〗 dt^2	
v_(b_(k+1))^w=v_(b_k)^w+∫_(t∈[k,k+1])▒〖(R_t^w a_t^b-g^w)dt〗	
〖"q" _("b" _"k+1" )^"w"  "=q" 〗_("b" _"k" )^"w" ⊗∫_(t∈[k,k+1])▒1/2 Ω(w_t^b) q_t^(b^k ) dt	(1)
	即当前时刻的状态可以通过上一时刻状态来迭代求得. 但这里有个问题在于积分中有个R_t^w，它是t时刻在world系下的旋转, 是一个要估计的量, 后面估计的过程中, 这个量会被不断的更新改变, 如果按照上面的式子, 那么每变一次就得重新积分. 把上次都乘一个旋转R_w^(b_t )转到b_t系下,就可以把那个讨厌的R从积分中抽出来, 这样不管R_w^(b_t )怎么变, 我们只需要一些简单的旋转矩阵相乘就能得到世界坐标系下的状态量。
直观上来理解: 位置,姿态,速度等, 它们的绝对量是跟参考坐标系的选取有关的, 如果参考坐标系移动了, 那么这些量也会跟着改变, 但某两个时刻之间的相对量p_(b_(k+1))^(b_k )，v_(b_(k+1))^(b^k )，q_(b_(k+1))^(b^k )是跟坐标选取无关的, 不管在哪个坐标系下看, 相对变化是不变的, 所以可以事先把这些不变的量求出来. p_(b_k)^w 〖"，q" 〗_("b" _"k" )^"w" 这些状态发生改变后, 可以通过矩阵乘法很容易的把相对量转成绝对量.
更加直观的理解: 把相邻两帧图像之间的一段时间的IMU预先积分起来, 得到两帧之间的IMU相对运动, 也就是把多个IMU观测变成一个运动观测, 它是不随某一时刻的绝对位姿改变而发生改变的。
我们可以下面部分相对b_k进行预积分：
α_(b_(k+1))^(b_k )=∬_(t∈[k,k+1])▒〖R_t^(b_k ) a_t^b 〗 dt^2	
β_(b_(k+1))^(b_k )=∫_(t∈[k,k+1])▒〖R_t^w a_t^b dt〗	
"R" _("b" _"k+1" )^(b_k )=∫_(t∈[k,k+1])▒R_t^(b_t ) [w_t^b×]t	(2)
其中[w_t^b×]表示w_t^b的反对成矩阵。α_(b_(k+1))^(b_k )，β_(b_(k+1))^(b_k )，"R" _("b" _"k+1" )^(b_k )分别表示位置，速度和旋转矩阵的预积分。根据(2)式，(1)式可以写成如下的离散形式：
p_(b_(k+1))^(b_k )=p_(b_k)^(b_0 )+"R" _("b" _"k" )^(b_0 ) v_(b_k)^(b_k ) Δ_t-(g^(b_0 ) 〖Δ_t〗^2)/2+"R" _("b" _"k+1" )^(b_0 ) α_(b_(k+1))^(b_k )	
v_(b_(k+1))^(b_(k+1) )="R" _("b" _"k" )^(b_(k+1) ) v_(b_k)^(b_k )-g^(b_0 ) Δ_t+"R" _("b" _"k" )^(b_(k+1) ) β_(b_(k+1))^(b_k )	
"R" _("b" _"k+1" )^(b_0 )="R" _("b" _"k" )^(b_0 ) "R" _("b" _"k+1" )^(b_k )	(3)

下面根据Christian Forster 的一篇文章中对IMU预积分的推导[2]。我们介绍一点IMU预积分的知识。
视觉惯性标定融合（Visual-Inertial Alignment）
1、陀螺仪偏差标定
对于相邻的两帧, 视觉有一个相对旋转q, IMU预积分有一个相对旋转R，标定的目的就是寻找一个最好的δb_g，使得两个相对旋转尽可能接近，q是不变的，δb_g的变化使得R变化，改变的斜率就是R对δb_g的Jacobian J_(b_g)^R。
min┬(b_g )⁡∑_(k∈B)▒〖||p_(b_0)^(b_k )⊗p_(b_(k+1))^(b_0 )-"R" _("b" _"k+1" )^(b_k )  ||〗^2 	(4)
"R" _("b" _"k+1" )^(b_k )≈R ̂_("b" _"k+1" )^(b_k )+(∂"R" _("b" _"k+1" )^(b_k ))/(∂b_g ) δb_g	
IMU角度和加速度的测量值可以通过下面线性化后的公式来表达，
w ̂_t^b= w_t^b+b_g+η_g	
a ̂_t^b= q^w (t)^T (a^w (t)+g^w )+b_a+η_a	(5)
这样根据上面计算出来的b_g，可以对α ̂_(b_(k+1))^(b_k )，β ̂_(b_(k+1))^(b_k )进行更新。
β ̂_("b" _"k+1" )^(b_k )≈β ̂_("b" _"k+1" )^(b_k )+(∂"β" _("b" _"k+1" )^(b_k ))/(∂b_g ) δb_g	
R ̂_("b" _"k+1" )^(b_k )≈R ̂_("b" _"k+1" )^(b_k )+(∂"R" _("b" _"k+1" )^(b_k ))/(∂b_g ) δb_g	(6)
2、速度，重力矢量和度量尺度初始化
此步骤需要估计的变量定义如下：
χ_I=[V_(b_0)^v,V_(b_1)^v,⋯V_(b_n)^v,g^v,s]	(7)
IMU预积分的结果和SFM的结果之间的关系可写成下式：
z ̂_("b" _"k+1" )^(b_k )= [■(α ̂_("b" _"k+1" )^(b_k )@β ̂_("b" _"k+1" )^(b_k ) )]= "H" _("b" _"k+1" )^(b_k ) χ_I+ "n" _("b" _"k+1" )^(b_k )	(8)
≈[■(■(q_v^(b_k ) 〖△t〗_k&0@〖-q〗_v^(b_k )&q_v^(b_k ) )&■(1/2 q_v^(b_k ) 〖△t〗_k^2&q_v^(b_k ) (P ̅_(b_(k+1))^v-P ̅_(b_k)^v)@q_v^(b_k ) 〖△t〗_k&0))][■(v_(b_k)^v@■(v_(b_(k+1))^v@g^v@s))]
α ̂_("b" _"k+1" )^(b_k )，β ̂_("b" _"k+1" )^(b_k )从IMU预积分得到，q_(b_k)^v，P ̅_(b_k)^v，P ̅_(b_(k+1))^v从vision SFM经过变换后可以得到。因为SFM拿到的是相机的R,t，要通过相机外参转成IMU坐标下的R,t. 转换公式为
q_(b_k)^v= q_(c_k)^v⨂q_b^c	
〖sP ̅〗_(b_k)^v= 〖sP ̅〗_(b_k)^v+ q_(c_k)^v P_b^c	(9)

可以转成如下的最小二乘问题来求解，我们可以得到相对视觉坐标系下的速度，重力向量和尺度参数。需要注意的是这里求解的是一个超定方程，因为对每一帧来说,除去首尾帧, 都有两组这个等式约束. 总的未知数是3n+3+1个, 约束方程的个数是6(n−1)个, 当n>2, 3n+3+1<6(n−1), 所以超定。
min┬(χ_I )⁡∑_(k∈B)▒〖||〖 z ̂〗_("b" _"k+1" )^(b_k )  - "H" _("b" _"k+1" )^(b_k ) χ_I  ||〗^2 	(10)
3、重力向量方向校正
上一步求出重力向量可以进一步校正, 因为重力加速度的模值通常是已知的(约9.8), 所以可以用重力加速度大小这个先验信息重复校正重力向量，但是|| g^(c_0 ) ||=9.8是一个非线性约束，很难直接加到上面的线性约束中求解，论文中将其转化为线性约束，思路是：设g的模值G已知，令g=Ge_g+w_1 e_1+w_2 e_2，其中，g是上一步求出的g ̂的单位向量，e_1，e_2是长成e_g的正切空间的两个正交的单位向量。然后将g=Ge_g+w_1 e_1+w_2 e_2带到上面的最小二乘约束方程，这时g的未知量从之前的3个变成了现在的w_1，w_2。重新求解可以得到一个更新后的g ̂，重复几次可以得到一个收敛的g ̂。需要注意的是每次迭代得到的g ̂需要进行归一化，这样才能保证校正的是重力向量的方向。
 
图1-3重力向量校正Tangent空间示意图
得到重力向量后，我们就可以将所有的初始化参数旋转到世界坐标系下，后面我们在此基础上构造紧耦合的非线性visual-inertial 估计器。

非线性VINS估计器
非线性状态估计器的优化变量如下：
χ=[x_0,x_1,⋯x_n,x_c^b,λ_0,λ_1,⋯λ_m]	
其中x_n=[p_(b_k)^w,v_(b_k)^w,q_(b_k)^w,b_a,b_g]，x_c^b=[p_c^b,q_c^b]，λ表示特征点的逆深度。
对应的非线性优化函数可以表示成如下形式：
min┬χ⁡{∑_(k∈B)▒〖〖〖||r_B (z ̅_(b_(k+1))^(b_k ),χ) ||〗^2〗_(P_(b_(k+1))^(b_k ) )+∑_((l,j)∈C)▒〖〖||r_C (z ̅_l^(c_j ),χ) ||〗^2〗_(P_l^(c_j ) ) 〗}	(11)
优化函数的前一部分是IMU运动模型的残差项，每相邻的两帧之间产生一个误残差；后一部分是视觉的残差项，单个特征点在相机投影下会产生一个残差。在论文的其他版本上优化函数还会包含marginalization后的先验信息所组成的残差项。
min┬χ⁡{|(|r_p-H_p χ|)|^2+∑_(k∈B)▒〖〖〖||r_B (z ̅_(b_(k+1))^(b_k ),χ) ||〗^2〗_(P_(b_(k+1))^(b_k ) )+∑_((l,j)∈C)▒〖〖||r_C (z ̅_l^(c_j ),χ) ||〗^2〗_(P_l^(c_j ) ) 〗}	     (12)

根据公式组(3)，IMU测量误差如下：
r_B (z ̅_(b_(k+1))^(b_k ),χ)=[■(〖δα〗_(b_(k+1))^(b_k )@〖δβ〗_(b_(k+1))^(b_k )@■(〖δθ〗_(b_(k+1))^(b_k )@δb_a@δb_g ))]=[■("R" _("b" _"0" )^(b_k ) (p_(b_(k+1))^(b_0 )-p_(b_k)^(b_0 )+(g^(b_0 ) 〖Δ_t〗^2)/2)-v_(b_k)^(b_k ) Δ_t 〖-α ̂〗_("b" _"k+1" )^(b_k )@"R" _("b" _"0" )^(b_k ) ("R" _("b" _"k+1" )^(b_0 ) v_(b_(k+1))^(b_(k+1) )+g^(b_0 ) Δ_t )-v_(b_k)^(b_k )-β ̂_("b" _"k+1" )^(b_k )@■(2〖[〖q ̂_(b_(k+1))^(b_k )〗^(-1)⨂〖q_(b_k)^(b_0 )〗^(-1)⨂〖q_(b_(k+1))^(b_0 )〗^(-1)]〗_xyz@b_(〖ab〗_(k+1) )-b_(〖ab〗_k )@b_(〖wb〗_(k+1) )-b_(〖wb〗_k ) ))]	(13)
视觉估计模型
r_C (z ̅_l^(c_j ),χ)=[■((f_(x_l)^(c_j ))/(f_(z_l)^(c_j ) )-u ̂_l^j@(f_(y_l)^(c_j ))/(f_(z_l)^(c_j ) )-v ̂_l^j )]
f_l^(c_j ) [■(f_(x_l)^(c_j )@f_(y_l)^(c_j )@f_(z_l)^(c_j ) )]=f_c^(b^(-1) ) (f_(b_j)^(b_0^(-1) ) (f_(b_i)^(b_0 )⋅f_c^b (λ_l [■(u_l^(c_i )@v_l^(c_i )@1)])))	(14)
重投影过程可以描述成下面的流程：
	i帧中图像中的点⇒i帧相机系⇒i帧IMU系⇒i帧世界系⇒j帧IMU系⇒j帧相机系。
	根据以上的误差模型，可以采用优化理论的算法进行迭代求解。
	在公式(12)中，优化函数还加入了边缘化的残差项，数学采用的也是Schur补的操作。为了处理悬停或匀速运动的情况，在VINS-Mono中，，引入了一种双通道边缘化方案。简单来说就是：如果倒数第二帧是关键帧, 则将最旧的位姿移出滑窗，如果倒数第二帧不是关键帧, 则将倒数第二帧位姿移出滑窗。下图分别描述了两种边缘化过程。
 

参考文献：
[1] Qin T, Shen S. Robust Initialization of Monocular Visual-Inertial Estimation on Aerial Robots[J].
[2] Yang Z, Shen S. Monocular Visual–Inertial State Estimation With Online Initialization and Camera–IMU Extrinsic Calibration[J]
Zhenfei.
[3] Li P, Shen S. Monocular Visual-Inertial State Estimation for Mobile Augmented Reality[J].
